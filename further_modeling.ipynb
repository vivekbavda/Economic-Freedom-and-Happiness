{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7711e08b",
   "metadata": {},
   "source": [
    "## Below are our imports for our data cleaning, exploratory data analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8902d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_validate, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Lasso, Ridge, RidgeCV, LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cde17a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "freedom_happiness_df = pd.read_csv('data/P5clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab50f47",
   "metadata": {},
   "source": [
    "## Test Linear Regression modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d821b85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1682 entries, 0 to 1681\n",
      "Data columns (total 22 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   year                              1682 non-null   float64\n",
      " 1   overall_score                     1682 non-null   float64\n",
      " 2   property_rights                   1682 non-null   float64\n",
      " 3   government_integrity              1682 non-null   float64\n",
      " 4   tax_burden                        1682 non-null   float64\n",
      " 5   government_spending               1682 non-null   float64\n",
      " 6   business_freedom                  1682 non-null   float64\n",
      " 7   labor_freedom                     1682 non-null   float64\n",
      " 8   monetary_freedom                  1682 non-null   float64\n",
      " 9   trade_freedom                     1682 non-null   float64\n",
      " 10  investment_freedom                1682 non-null   float64\n",
      " 11  financial_freedom                 1682 non-null   float64\n",
      " 12  log_gdp_per_capita                1682 non-null   float64\n",
      " 13  social_support                    1682 non-null   float64\n",
      " 14  healthy_life_expectancy_at_birth  1682 non-null   float64\n",
      " 15  choice_freedom                    1682 non-null   float64\n",
      " 16  generosity                        1682 non-null   float64\n",
      " 17  perceptions_of_corruption         1682 non-null   float64\n",
      " 18  positive_affect                   1682 non-null   float64\n",
      " 19  negative_affect                   1682 non-null   float64\n",
      " 20  country_name                      1682 non-null   object \n",
      " 21  life_ladder                       1682 non-null   float64\n",
      "dtypes: float64(21), object(1)\n",
      "memory usage: 302.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# #drop all nulls and duplicates\n",
    "# #        We'll liekly want to revisit and do some more precise cleaning, \n",
    "# #        but in the interest of viewing correleations and establishing \n",
    "# #        baseline performance we'll just drop everything for now\n",
    "\n",
    "# # Any duplicate rows? No\n",
    "len(freedom_happiness_df[freedom_happiness_df.duplicated()])\n",
    "# drop nulls\n",
    "freedom_happiness_df.dropna(inplace=True)\n",
    "freedom_happiness_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e1f9eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = freedom_happiness_df.drop(columns=['year', 'life_ladder', 'overall_score', 'country_name'])\n",
    "y = freedom_happiness_df['life_ladder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d907ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainging R-squared: 0.7677704554917241\n",
      "Testing R-squared: 0.7768002853217872\n",
      "Scaled trainging R-squared: 0.7677704554917241\n",
      "Scaled testing R-squared: 0.7768002853217872\n"
     ]
    }
   ],
   "source": [
    "# Linear regression (using ALL features to predict 'overall_score', not just economic features)\n",
    "\n",
    "# assign\n",
    "# exclude = ['country_name', 'life_ladder']\n",
    "# X_features = [i for i in freedom_happiness_df if i not in exclude]\n",
    "# X = freedom_happiness_df[X_features]\n",
    "# y = freedom_happiness_df['life_ladder']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "# scale\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)\n",
    "\n",
    "# fit / score\n",
    "lm = linear_model.LinearRegression(n_jobs = -1)\n",
    "\n",
    "lm.fit(X_train, y_train)\n",
    "print(f'Trainging R-squared: {lm.score(X_train, y_train)}')\n",
    "print(f'Testing R-squared: {lm.score(X_test, y_test)}')\n",
    "\n",
    "lm.fit(X_train_sc, y_train)\n",
    "print(f'Scaled trainging R-squared: {lm.score(X_train_sc, y_train)}')\n",
    "print(f'Scaled testing R-squared: {lm.score(X_test_sc, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b6825ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "life_ladder                         1.000000\n",
       "log_gdp_per_capita                  0.786262\n",
       "healthy_life_expectancy_at_birth    0.740277\n",
       "social_support                      0.709317\n",
       "government_integrity                0.684178\n",
       "property_rights                     0.658343\n",
       "business_freedom                    0.601996\n",
       "overall_score                       0.589604\n",
       "financial_freedom                   0.550077\n",
       "trade_freedom                       0.526725\n",
       "positive_affect                     0.520366\n",
       "choice_freedom                      0.515615\n",
       "investment_freedom                  0.459059\n",
       "monetary_freedom                    0.294137\n",
       "labor_freedom                       0.213469\n",
       "generosity                          0.180719\n",
       "year                                0.046073\n",
       "tax_burden                         -0.279132\n",
       "negative_affect                    -0.301800\n",
       "government_spending                -0.428348\n",
       "perceptions_of_corruption          -0.430875\n",
       "Name: life_ladder, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freedom_happiness_df.corr()['life_ladder'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58667856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'overall_score', 'property_rights', 'government_integrity',\n",
       "       'tax_burden', 'government_spending', 'business_freedom',\n",
       "       'labor_freedom', 'monetary_freedom', 'trade_freedom',\n",
       "       'investment_freedom', 'financial_freedom', 'log_gdp_per_capita',\n",
       "       'social_support', 'healthy_life_expectancy_at_birth', 'choice_freedom',\n",
       "       'generosity', 'perceptions_of_corruption', 'positive_affect',\n",
       "       'negative_affect', 'country_name', 'life_ladder'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freedom_happiness_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2e2a366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainging R-squared: 0.5176527266483792\n",
      "Testing R-squared: 0.571910564905197\n",
      "Scaled trainging R-squared: 0.5176527266483792\n",
      "Scaled testing R-squared: 0.571910564905197\n"
     ]
    }
   ],
   "source": [
    "# Linear regression (using exclusively economic features to predict happiness)\n",
    "\n",
    "#assign\n",
    "exclude = ['life_ladder', 'country_name', 'year', 'overall_score', 'country_year', 'judicial_effectiveness', 'fiscal_health']\n",
    "econ_cols = ['property_rights', 'government_integrity',\n",
    "       'tax_burden', 'government_spending', 'business_freedom',\n",
    "       'labor_freedom', 'monetary_freedom', 'trade_freedom',\n",
    "       'investment_freedom', 'financial_freedom']\n",
    "happiness_cols = ['log_gdp_per_capita',\n",
    "       'social_support', 'healthy_life_expectancy_at_birth', 'choice_freedom',\n",
    "       'generosity', 'perceptions_of_corruption', 'positive_affect',\n",
    "       'negative_affect', 'country_name', 'life_ladder']\n",
    "\n",
    "X_features = [i for i in econ_cols if i not in exclude]\n",
    "# X_features = econ_freedom_df.drop(columns = ['country_name', 'life_ladder', 'country_year'])\n",
    "X2 = freedom_happiness_df[X_features]\n",
    "y2 = freedom_happiness_df['life_ladder']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, random_state = 42)\n",
    "\n",
    "# scale\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)\n",
    "\n",
    "# fit / score\n",
    "lm = linear_model.LinearRegression(n_jobs = -1)\n",
    "\n",
    "lm.fit(X_train, y_train)\n",
    "print(f'Trainging R-squared: {lm.score(X_train, y_train)}')\n",
    "print(f'Testing R-squared: {lm.score(X_test, y_test)}')\n",
    "\n",
    "lm.fit(X_train_sc, y_train)\n",
    "print(f'Scaled trainging R-squared: {lm.score(X_train_sc, y_train)}')\n",
    "print(f'Scaled testing R-squared: {lm.score(X_test_sc, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00093547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainging R-squared: 0.7563467159669359\n",
      "Testing R-squared: 0.7582342047514951\n",
      "Scaled trainging R-squared: 0.7563467159669359\n",
      "Scaled testing R-squared: 0.7582342047514955\n"
     ]
    }
   ],
   "source": [
    "# Linear regression (using exclusively happiness features to predict happiness)\n",
    "\n",
    "# assign\n",
    "exclude = ['life_ladder', 'country_name', 'year', 'overall_score', 'country_year', 'judicial_effectiveness', 'fiscal_health']\n",
    "X_features = [i for i in happiness_cols if i not in exclude]\n",
    "X3 = freedom_happiness_df[X_features]\n",
    "y3 = freedom_happiness_df['life_ladder']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, random_state = 42)\n",
    "\n",
    "# scale\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)\n",
    "\n",
    "# fit / score\n",
    "lm = linear_model.LinearRegression(n_jobs = -1)\n",
    "\n",
    "lm.fit(X_train, y_train)\n",
    "print(f'Trainging R-squared: {lm.score(X_train, y_train)}')\n",
    "print(f'Testing R-squared: {lm.score(X_test, y_test)}')\n",
    "\n",
    "lm.fit(X_train_sc, y_train)\n",
    "print(f'Scaled trainging R-squared: {lm.score(X_train_sc, y_train)}')\n",
    "print(f'Scaled testing R-squared: {lm.score(X_test_sc, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb1d3dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient values of the Model are  [-9.51392991e-04 -2.46037977e-03 -6.10654731e-03 -1.79073962e-03\n",
      "  1.70574055e-03 -3.13302768e-03  1.68962193e-03 -7.17713405e-03\n",
      "  1.50911622e-03  3.35278249e-03  3.74228605e-01  2.12374903e+00\n",
      "  2.64441263e-02  3.19093075e-01  5.24142204e-01 -6.20544086e-01\n",
      "  1.85619855e+00  1.27616792e-01]\n",
      "Intercept value is  -1.5974285775967276\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=.2, random_state=41)\n",
    "#Instantiate the estimator\n",
    "lr = LinearRegression(n_jobs=-1)\n",
    "\n",
    "#fit estimator\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#predict to score\n",
    "odd=lr.predict(X_test)\n",
    "\n",
    "# The intercept and Coefficients\n",
    "print('Coefficient values of the Model are ', lr.coef_)\n",
    "print('Intercept value is ', lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ef25379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77897998 0.80691654 0.76764847 0.74254582 0.73999068]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.77 Â± 0.05'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntr=cross_val_score(lr, X_train, y_train, cv=5, n_jobs = -1) \n",
    "print(ntr)\n",
    "f'{round(np.mean(ntr), 2)} \\u00B1 {round(2 * np.std(ntr), 2)}'\n",
    "#I believe there are outliers and that my model is overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "924947ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtrainscore: 0.7656583339455707\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "#scale\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)\n",
    "\n",
    "# fit LassoCV\n",
    "lsv=LassoCV(cv = 10)\n",
    "lsv.fit(X_train_sc, y_train)\n",
    "oddlasso=lsv.predict(X_test_sc)\n",
    "\n",
    "#R2 score on Xtrain\n",
    "print('Xtrainscore:', lsv.score(X_train_sc, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8778bf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "property_rights 0.0\n",
      "government_spending -0.0\n",
      "business_freedom 0.0\n",
      "labor_freedom -0.0\n",
      "monetary_freedom 0.0\n",
      "trade_freedom 0.0\n",
      "investment_freedom 0.0\n",
      "negative_affect -0.0\n"
     ]
    }
   ],
   "source": [
    "l_alphas = np.arange(0.01, .10, 0.05)\n",
    "\n",
    "def lasso_coefs(X, Y, alphas):\n",
    "    coefs = []\n",
    "    lasso_reg = Lasso()\n",
    "    for a in alphas:\n",
    "        lasso_reg.set_params(alpha=a)\n",
    "        lasso_reg.fit(X, Y)\n",
    "        coefs.append(lasso_reg.coef_)\n",
    "    return coefs\n",
    "\n",
    "# model using lasso_coefs function from above\n",
    "l_coefs = lasso_coefs(X_train_sc, y_train, l_alphas)\n",
    "\n",
    "features_coefs_df = pd.DataFrame(l_coefs, columns =X.columns)\n",
    "features_coefs_df['alpha'] = l_alphas\n",
    "for col, coef in features_coefs_df.iloc[features_coefs_df.index.max()]\\\n",
    "                              .iteritems():\n",
    "    if not coef:\n",
    "        print(col, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86f04ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_filter_out = [col for col, coef in features_coefs_df\\\n",
    "                                              .iloc[features_coefs_df.index.max()]\\\n",
    "                                              .iteritems() if not coef]\n",
    "listoffeatures=['property_rights', 'government_integrity',\n",
    "       'tax_burden', 'government_spending', 'business_freedom',\n",
    "       'labor_freedom', 'monetary_freedom', 'trade_freedom',\n",
    "       'investment_freedom', 'financial_freedom', 'log_gdp_per_capita',\n",
    "       'social_support', 'healthy_life_expectancy_at_birth', 'choice_freedom',\n",
    "       'generosity', 'perceptions_of_corruption', 'positive_affect',\n",
    "       'negative_affect']\n",
    "freedom_features = [col for col in listoffeatures\\\n",
    "                      if col not in columns_to_filter_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04421756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freedom_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be096429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['government_integrity',\n",
       " 'tax_burden',\n",
       " 'financial_freedom',\n",
       " 'log_gdp_per_capita',\n",
       " 'social_support',\n",
       " 'healthy_life_expectancy_at_birth',\n",
       " 'choice_freedom',\n",
       " 'generosity',\n",
       " 'perceptions_of_corruption',\n",
       " 'positive_affect']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freedom_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f794dd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7677115697287443\n"
     ]
    }
   ],
   "source": [
    "#Instantiate\n",
    "ridge_reg = RidgeCV()\n",
    "\n",
    "#Fit the model\n",
    "ridge_reg.fit(X_train_sc, y_train)\n",
    "\n",
    "#Predict\n",
    "oddridge=ridge_reg.predict(X_test_sc)\n",
    "\n",
    "# X_train_sc R2 score below\n",
    "print(ridge_reg.score(X_train_sc, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea917f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF 0.882 +- 0.019\n"
     ]
    }
   ],
   "source": [
    "# X=StandardScaler().fit_transform(X)\n",
    "\n",
    "rf=RandomForestRegressor()\n",
    "rf_scores=cross_val_score(rf, X, y, cv=KFold(n_splits=10, shuffle=True, random_state=42))\n",
    "print('RF', round (rf_scores.mean(), 3), '+-', round (2 *rf_scores.std(), 3))\n",
    "\n",
    "\n",
    "# rfpredictions= cross_val_predict(rf, X, y, cv=KFold(n_splits=5, shuffle=True, random_state=42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4161e6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rfpipe=Pipeline([('ss', StandardScaler()),\n",
    "# #                 ('rf', RandomForestRegressor())])\n",
    "# pipe_param={'rf__n_estimators':[10,25, 50, 100],\n",
    "#     'rf__criterion':['mse'],\n",
    "#     'rf__max_depth':[None],\n",
    "#     'rf__min_samples_split':[2,5,10,15],\n",
    "#     'rf__min_samples_leaf':[1,3,5,7],\n",
    "#     'rf__min_weight_fraction_leaf':[0,1,2],\n",
    "#     'rf__max_features':['auto','sqrt','log2',None],\n",
    "#     'rf__max_leaf_nodes':[None],\n",
    "#     'rf__min_impurity_decrease':[0],\n",
    "#     'rf__min_impurity_split':[None],\n",
    "#     'rf__bootstrap':[True],\n",
    "#     'rf__oob_score': [True,False],\n",
    "#     'rf__n_jobs':[-1],\n",
    "#     'rf__random_state': [42],\n",
    "#     'rf__verbose':[0],\n",
    "#     'rf__warm_start':[False,True],\n",
    "#     'rf__ccp_alpha':[0],\n",
    "#     'rf__max_samples':[None]}\n",
    "\n",
    "# # rfpipe_gridsearcher=GridSearchCV(rf, pipe_param, verbose=2)\n",
    "\n",
    "# rf_gridsearcher=GridSearchCV(rf, pipe_param, verbose=0)\n",
    "\n",
    "\n",
    "# rf_gridsearcher.fit(X,y)\n",
    "\n",
    "# rf_gridsearcher.param_grid\n",
    "\n",
    "# rf_gridsearcher.best_score_\n",
    "\n",
    "# rf_gridsearcher.best_estimator_\n",
    "\n",
    "# rf_gridsearcher.best_params_\n",
    "\n",
    "# rf_gridsearcher.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4024e54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-e08fbedfabcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'# rfpipe=Pipeline([(\\'ss\\', StandardScaler()),\\n#                 (\\'rf\\', RandomForestRegressor())])\\n# pipe_param={\\'max_depth\\':[2, 5, 10, None]}\\n\\npipe_param={\\'n_estimators\\':[50, 100],\\n            \\'criterion\\':[\"mse\"],\\n            \\'max_depth\\':[None],\\n            \\'min_samples_split\\':[2,5],\\n            \\'min_samples_leaf\\':[1,3,5],\\n            \\'min_weight_fraction_leaf\\':[0,1,2],\\n            \\'max_features\\':[\\'auto\\',\\'sqrt\\',\\'log2\\',None]}\\n\\n\\n# n_estimators=100,\\n#     *,\\n#     criterion=\\'mse\\',\\n#     max_depth=None,\\n#     min_samples_split=2,\\n#     min_samples_leaf=1,\\n#     min_weight_fraction_leaf=0.0,\\n#     max_features=\\'auto\\',\\n    \\n    \\n# rfpipe_gridsearcher=GridSearchCV(rf, pipe_param, verbose=2)\\n\\nrf_gridsearcher=GridSearchCV(rf, pipe_param, verbose=1)\\n\\nrf_gridsearcher.fit(X,y)\\n\\nrf_gridsearcher.param_grid\\n\\nprint(rf_gridsearcher.best_score_)\\n\\nprint(rf_gridsearcher.best_estimator_)\\n\\nprint(rf_gridsearcher.best_params_)\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2397\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2398\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2399\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2400\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_INT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             trees = [self._make_estimator(append=False,\n\u001b[0m\u001b[1;32m    378\u001b[0m                                           random_state=random_state)\n\u001b[1;32m    379\u001b[0m                      for i in range(n_more_estimators)]\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_INT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m             trees = [self._make_estimator(append=False,\n\u001b[0m\u001b[1;32m    378\u001b[0m                                           random_state=random_state)\n\u001b[1;32m    379\u001b[0m                      for i in range(n_more_estimators)]\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0m_set_random_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_set_random_states\u001b[0;34m(estimator, random_state)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mto_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'random_state'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__random_state'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mto_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \"\"\"\n\u001b[1;32m    193\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    174\u001b[0m                                    % (cls, init_signature))\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m# Extract and sort argument names excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    174\u001b[0m                                    % (cls, init_signature))\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m# Extract and sort argument names excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# rfpipe=Pipeline([('ss', StandardScaler()),\n",
    "#                 ('rf', RandomForestRegressor())])\n",
    "# pipe_param={'max_depth':[2, 5, 10, None]}\n",
    "\n",
    "pipe_param={'n_estimators':[50, 100],\n",
    "            'criterion':[\"mse\"],\n",
    "            'max_depth':[None],\n",
    "            'min_samples_split':[2,5],\n",
    "            'min_samples_leaf':[1,3,5],\n",
    "            'min_weight_fraction_leaf':[0,1,2],\n",
    "            'max_features':['auto','sqrt','log2',None]}\n",
    "\n",
    "\n",
    "# n_estimators=100,\n",
    "#     *,\n",
    "#     criterion='mse',\n",
    "#     max_depth=None,\n",
    "#     min_samples_split=2,\n",
    "#     min_samples_leaf=1,\n",
    "#     min_weight_fraction_leaf=0.0,\n",
    "#     max_features='auto',\n",
    "    \n",
    "    \n",
    "# rfpipe_gridsearcher=GridSearchCV(rf, pipe_param, verbose=2)\n",
    "\n",
    "rf_gridsearcher=GridSearchCV(rf, pipe_param, verbose=1)\n",
    "\n",
    "rf_gridsearcher.fit(X,y)\n",
    "\n",
    "rf_gridsearcher.param_grid\n",
    "\n",
    "print(rf_gridsearcher.best_score_)\n",
    "\n",
    "print(rf_gridsearcher.best_estimator_)\n",
    "\n",
    "print(rf_gridsearcher.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91efb3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestRegressor().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83c98075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5be7c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe559809550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "-11.552700996398926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'d_drop1': 0.25,\n",
       " 'epochs': 20,\n",
       " 'layer_one_neurons': 32,\n",
       " 'layer_two_neurons': 32}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_fn(layer_one_neurons=32, layer_two_neurons=32, d_drop1=.25):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer_one_neurons, activation='relu', input_shape=(18,),kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(d_drop1))\n",
    "    model.add(Dense(layer_two_neurons,activation='relu'))\n",
    "    model.add(Dense(1, activation=None))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "nn = KerasRegressor(build_fn=model_fn, epochs=1000, batch_size=512, verbose=0)\n",
    "#scikilt learn complied model--CV is reduced t o 2 for time-do not do in work\n",
    "params={ 'epochs':[20],\n",
    "        'layer_one_neurons':[32],\n",
    "       'layer_two_neurons':[32],\n",
    "      'd_drop1': [.25]}\n",
    "gs= GridSearchCV(nn, param_grid=params, cv=5)\n",
    "gs.fit(X_train_sc, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92a0c213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5076325419382908"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred= gs.predict(X_test_sc)\n",
    "metrics.r2_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6da7d89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient values of the Model are  [-0.00285394 -0.00918781  0.00281967  0.365929    2.02752205  0.02784777\n",
      "  0.30044074  0.47201792 -0.57784028  1.80322559]\n",
      "Intercept value is  -1.7725794035546514\n",
      "[0.76724854 0.7737447  0.77479708 0.73886825 0.74067881]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.76 Â± 0.03'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "G=X[freedom_features]\n",
    "X_train, X_test, y_train, y_test= train_test_split(G, y, test_size=.2, random_state=41)\n",
    "#Instantiate the estimator\n",
    "lr = LinearRegression(n_jobs=-1)\n",
    "\n",
    "#fit estimator\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#predict to score\n",
    "odd=lr.predict(X_test)\n",
    "\n",
    "# The intercept and Coefficients\n",
    "print('Coefficient values of the Model are ', lr.coef_)\n",
    "print('Intercept value is ', lr.intercept_)\n",
    "\n",
    "ntr=cross_val_score(lr, G, y, cv=5, n_jobs = -1) \n",
    "print(ntr)\n",
    "f'{round(np.mean(ntr), 2)} \\u00B1 {round(2 * np.std(ntr), 2)}'\n",
    "#I believe there are outliers and that my model is overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6befc987",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (1682,18) into shape (1682,10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-466c81cf5f88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_with_intercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_with_intercept\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_with_intercept\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbeta_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_with_intercept\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX_with_intercept\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX_with_intercept\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (1682,18) into shape (1682,10)"
     ]
    }
   ],
   "source": [
    "N = len(G)\n",
    "p = len(G.columns) + 1  # plus one because LinearRegression adds an intercept term\n",
    "\n",
    "X_with_intercept = np.empty(shape=(N, p), dtype=np.float)\n",
    "X_with_intercept[:, 0] = 1\n",
    "X_with_intercept[:, 1:p] = X.values\n",
    "\n",
    "beta_hat = np.linalg.inv(X_with_intercept.T @ X_with_intercept) @ X_with_intercept.T @ y.values\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b6bdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X)\n",
    "residuals = y.values - y_hat\n",
    "residual_sum_of_squares = residuals.T @ residuals\n",
    "sigma_squared_hat = residual_sum_of_squares[0, 0] / (N - p)\n",
    "var_beta_hat = np.linalg.inv(X_with_intercept.T @ X_with_intercept) * sigma_squared_hat\n",
    "for p_ in range(p):\n",
    "    standard_error = var_beta_hat[p_, p_] ** 0.5\n",
    "    print(f\"SE(beta_hat[{p_}]): {standard_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2581be10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522acdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
