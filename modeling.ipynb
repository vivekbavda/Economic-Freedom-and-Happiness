{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7711e08b",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee26ed8b",
   "metadata": {},
   "source": [
    "We know from our EDA that we have some outliers in our data. We also know that metrics such as Mean-Squared-Error and Root-Mean-Squared-Error are very sensetive to outliers. We decided to try both MAE and MSE to see which score would be better. And also, we will look at the difference between train and test score to see if our model overfitt or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ff87b8",
   "metadata": {},
   "source": [
    "## 1. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8902d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cde17a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "freedom_happiness_df = pd.read_csv('data/P5clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab50f47",
   "metadata": {},
   "source": [
    "## 2. Test Linear Regression model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e1f9eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# We wanted to exclude columns (year, life_lader, overall_score and country name from our features)\n",
    "# 'overall_score' is an average of all features, use it instead of all economic features to try different variations.\n",
    "\n",
    "X = freedom_happiness_df.drop(columns=['year', 'life_ladder', 'overall_score', 'country_name'])\n",
    "y = freedom_happiness_df['life_ladder']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "#not necessary for linear regression\n",
    "#will be use for Lasso and Ridge regularization \n",
    "# ss = StandardScaler()\n",
    "# X_train = ss.fit_transform(X_train)\n",
    "# X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d907ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.76761022056187\n",
      "test score: 0.7766130949202299\n",
      "----------------------------------------\n",
      "MSE: 0.28097939109588643\n",
      "MAE: 0.4067081701200669\n",
      "R2: 0.7766130949202299\n"
     ]
    }
   ],
   "source": [
    "# Modelimg\n",
    "\n",
    "lm = LinearRegression(n_jobs = -1)\n",
    "\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "print(f'train score: {lm.score(X_train, y_train)}')\n",
    "print(f'test score: {lm.score(X_test, y_test)}')\n",
    "\n",
    "odd=lm.predict(X_test)\n",
    "\n",
    "print('----------------------------------------')\n",
    "print('MSE:', mean_squared_error(y_test, odd))\n",
    "print('MAE:', mean_absolute_error(y_test, odd))\n",
    "print(f'R2: {r2_score(y_test, odd)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82071fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.07140007e-04, -4.40575272e-03, -5.68924659e-03, -1.55615557e-03,\n",
       "        2.26666663e-03, -2.65045806e-03,  9.00115811e-04, -7.27553026e-03,\n",
       "        1.47926983e-03,  4.47976755e-03,  4.04550854e-01,  1.91293243e+00,\n",
       "        2.23871977e-02,  5.55771200e-01,  3.66515479e-01, -5.79755751e-01,\n",
       "        1.95625631e+00,  1.95297406e-02])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "955f508f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.457</td>\n",
       "      <td>5.440353</td>\n",
       "      <td>0.016647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.671</td>\n",
       "      <td>4.058061</td>\n",
       "      <td>-0.387061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.671</td>\n",
       "      <td>7.071452</td>\n",
       "      <td>0.599548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.294</td>\n",
       "      <td>5.423991</td>\n",
       "      <td>0.870009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.004</td>\n",
       "      <td>4.413869</td>\n",
       "      <td>0.590131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  Predicted  Difference\n",
       "0   5.457   5.440353    0.016647\n",
       "1   3.671   4.058061   -0.387061\n",
       "2   7.671   7.071452    0.599548\n",
       "3   6.294   5.423991    0.870009\n",
       "4   5.004   4.413869    0.590131"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can look at our predictions how close we are to original\n",
    "\n",
    "pred_test_df = pd.DataFrame(data=[i for i in zip(y_test[:5].values, odd[:5])], columns = ['Actual', 'Predicted'])\n",
    "pred_test_df['Difference'] = pred_test_df['Actual'] - pred_test_df['Predicted']\n",
    "pred_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77d9522",
   "metadata": {},
   "source": [
    "- Our predictions are pretty good, but the model is a little bit overfit. The standard scaler didn't have any affect to our model and we decided don't use it for next few models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c311667f",
   "metadata": {},
   "source": [
    "## 3. Linear Regression and Economic Features Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c8bc616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We would like to see how economic features would affect our model and happiness.\n",
    "\n",
    "Economic_features = freedom_happiness_df.drop(columns = ['log_gdp_per_capita',\n",
    "       'social_support', 'healthy_life_expectancy_at_birth', 'choice_freedom',\n",
    "       'generosity', 'perceptions_of_corruption', 'positive_affect',\n",
    "       'negative_affect', 'country_name', 'life_ladder','life_ladder',\n",
    "       'country_name', 'year', 'overall_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2e2a366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " economic train: 0.5173878163687027\n",
      " economic test: 0.5716161347505673\n",
      "----------------------------------------\n",
      "MSE: 0.538827634368745\n",
      "MAE: 0.5696537526417473\n",
      "R2: 0.5716161347505673\n"
     ]
    }
   ],
   "source": [
    "# Modeling\n",
    "\n",
    "X2 = Economic_features\n",
    "y2 = freedom_happiness_df['life_ladder']\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, random_state = 42)\n",
    "\n",
    "lm.fit(X_train2, y_train2)\n",
    "\n",
    "odd2=lm.predict(X_test2)\n",
    "\n",
    "print(f' economic train: {lm.score(X_train2, y_train2)}')\n",
    "print(f' economic test: {lm.score(X_test2, y_test2)}')\n",
    "print('----------------------------------------')\n",
    "print('MSE:', mean_squared_error(y_test2, odd2))\n",
    "print('MAE:', mean_absolute_error(y_test2, odd2))\n",
    "print(f'R2: {r2_score(y_test2, odd2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4748152",
   "metadata": {},
   "source": [
    "- our score dropped and we have very overfitting model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10408084",
   "metadata": {},
   "source": [
    "## 3. Linear Regression and features from happiness dataset/report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86cc1b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Happiness_features = freedom_happiness_df.drop(columns = ['life_ladder', 'country_name', 'year', 'overall_score','property_rights', \n",
    "                                   'government_integrity', 'tax_burden', 'government_spending', 'business_freedom',\n",
    "                                     'labor_freedom','monetary_freedom', 'trade_freedom', 'investment_freedom','financial_freedom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00093547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 happiness train: 0.7562259743234682\n",
      "R2 happiness test: 0.7582893286308156\n"
     ]
    }
   ],
   "source": [
    "# Modeling\n",
    "\n",
    "X3 = Happiness_features\n",
    "y3 = freedom_happiness_df['life_ladder']\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, random_state = 42)\n",
    "\n",
    "lm.fit(X_train3, y_train3)\n",
    "\n",
    "print(f'R2 happiness train: {lm.score(X_train3, y_train3)}')\n",
    "print(f'R2 happiness test: {lm.score(X_test3, y_test3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c9d55",
   "metadata": {},
   "source": [
    "- This is very close to our 1st model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e533f37c",
   "metadata": {},
   "source": [
    "## 4.  Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d09e483",
   "metadata": {},
   "source": [
    "We wanted to see if models such as Lasso or Ridge could improve our score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7268b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score 0.59478273468815\n",
      "testing score 0.6207398869180571\n",
      "----------------------------------------\n",
      "MSE 0.477039043997086\n",
      "MAE: 0.5562621367664375\n",
      "R2: 0.6207398869180571\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "lasso_pred = lasso.predict(X_test)\n",
    "\n",
    "print('training score', lasso.score(X_train, y_train))\n",
    "print('testing score', lasso.score(X_test,y_test))\n",
    "print('----------------------------------------')\n",
    "print('MSE', mean_squared_error(y_test, lasso_pred))\n",
    "print('MAE:', mean_absolute_error(y_test, lasso_pred))\n",
    "print(f'R2: {r2_score(y_test, lasso_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3243cf24",
   "metadata": {},
   "source": [
    "## 5.  Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f794dd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score 0.7672226765615445\n",
      "testing score 0.7763920000098308\n",
      "----------------------------------------\n",
      "MSE 0.28125748758178465\n",
      "MAE 0.40798613116164795\n",
      "R2: 0.7763920000098308\n"
     ]
    }
   ],
   "source": [
    "#Instantiate\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "ridge_pred = ridge.predict(X_test)\n",
    "\n",
    "print('training score', ridge.score(X_train, y_train))\n",
    "print('testing score', ridge.score(X_test, y_test))\n",
    "print('----------------------------------------')\n",
    "print('MSE', mean_squared_error(y_test, ridge_pred))\n",
    "print('MAE', mean_absolute_error(y_test,ridge_pred))\n",
    "print(f'R2: {r2_score(y_test, ridge_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13035181",
   "metadata": {},
   "source": [
    "# Random Forest Regressor (no tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaf09e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9827127119962527"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfc1bfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8734873757836586"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb941c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d15940b",
   "metadata": {},
   "source": [
    "## 5. GridSearch best parameters for Random Forest to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4024e54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n",
      "Best score: 0.8421362811420161\n",
      "Best Estimator: RandomForestRegressor(min_samples_leaf=10, min_samples_split=10,\n",
      "                      n_estimators=300)\n",
      "Best parameters: {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Search for the best param for Random Forest\n",
    "\n",
    "rf=RandomForestRegressor()\n",
    "\n",
    "pipe_param={'n_estimators':[50,300],\n",
    "            'max_depth':[None, 2 ],\n",
    "            'min_samples_split':[10, 30],\n",
    "             'min_samples_leaf': [10, 20, 30, 40],\n",
    "             'max_features':['auto',0.1]}\n",
    "    \n",
    "\n",
    "rf_gridsearcher=GridSearchCV(rf, pipe_param, verbose=1)\n",
    "\n",
    "rf_gridsearcher.fit(X_train,y_train)\n",
    "\n",
    "print('Best score:', rf_gridsearcher.best_score_)\n",
    "print('Best Estimator:', rf_gridsearcher.best_estimator_)\n",
    "print('Best parameters:', rf_gridsearcher.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3890acd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method RegressorMixin.score of RandomForestRegressor()>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2235af86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    }
   ],
   "source": [
    "# Search for the best param for Random Forest\n",
    "\n",
    "rf=RandomForestRegressor()\n",
    "\n",
    "# pipe_param={'n_estimators':[50,300],\n",
    "#             'max_depth':[None, 2 ],\n",
    "#             'min_samples_split':[10, 30],\n",
    "#              'min_samples_leaf': [10, 20, 30, 40],\n",
    "#              'max_features':['auto',0.1]}\n",
    "    \n",
    "\n",
    "rf_gridsearcher=GridSearchCV(rf, pipe_param, verbose=1)\n",
    "\n",
    "rf_gridsearcher.fit(X_train,y_train)\n",
    "\n",
    "print('Best score:', rf_gridsearcher.best_score_)\n",
    "print('Best Estimator:', rf_gridsearcher.best_estimator_)\n",
    "print('Best parameters:', rf_gridsearcher.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d4bdd8",
   "metadata": {},
   "source": [
    "## 6. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfeceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "\n",
    "rf=RandomForestRegressor(n_estimators = 1000, min_samples_leaf= 80, max_features = 0.5,  min_samples_split=60, max_samples =800)\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "print(f'train score:{rf.score(X_train, y_train)}')\n",
    "print(f'test score: {rf.score(X_test, y_test)}')\n",
    "print('----------------------------------------')\n",
    "print('MSE:', mean_squared_error(y_test, rf_pred))\n",
    "print('MAE:', mean_absolute_error(y_test, rf_pred))\n",
    "print(f'R2: {r2_score(y_test, rf_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7d6ecd",
   "metadata": {},
   "source": [
    "## 7. Ridge and Best Features from EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a69a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing only features that corellated more than %50\n",
    "\n",
    "X4 = freedom_happiness_df[[ 'overall_score', 'perceptions_of_corruption','log_gdp_per_capita', \n",
    "                           'social_support', 'healthy_life_expectancy_at_birth','government_integrity']]\n",
    "y4 = freedom_happiness_df.life_ladder\n",
    "\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(X4, y4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab54491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "\n",
    "ridge.fit(X_train4, y_train4)\n",
    "\n",
    "ridge_pred4 = ridge.predict(X_test4)\n",
    "\n",
    "print('training score', ridge.score(X_train4, y_train4))\n",
    "print('testing score', ridge.score(X_test4,y_test4))\n",
    "print('----------------------------------------')\n",
    "print('MSE', mean_squared_error(y_test4, ridge_pred4))\n",
    "print('MAE:', mean_absolute_error(y_test4, ridge_pred4))\n",
    "print(f'R2: {r2_score(y_test4, ridge_pred4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19722082",
   "metadata": {},
   "source": [
    "## 8. Plot The best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ade86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.regplot(y_test, odd, scatter_kws={\"s\": 20});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e52850",
   "metadata": {},
   "source": [
    "## 9. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bb888e",
   "metadata": {},
   "source": [
    "In this notebook we've tried 4 models Linear Regression, Lasso, Ridge and Random Forest to predict happiness. We used a Grid Search to find better parameters for our model. We also wanted to see how just features from freedom dataset and features from happiness dataset would affect our model. Our results were following:\n",
    "\n",
    "| MODEL                            | SCORE                 |\n",
    "|----------------------------------|-----------------------|\n",
    "| Linear Regression + all features |  MSE: 0.28            |\n",
    "|                                  |  MAE: 0.41            |\n",
    "|                                  |  R2:  0.78            |\n",
    "|----------------------------------|-----------------------|\n",
    "| Linear Regression +              | train score: 0.52     |\n",
    "| Economic features                | R2 test score: 0.57   |\n",
    "|----------------------------------|-----------------------|\n",
    "| Linear Regression +              | train score: 0.76     |\n",
    "| Happiness features               | test score: 0.76      |\n",
    "|----------------------------------|-----------------------|\n",
    "|                                  | train score: 0.59     |\n",
    "|                                  | test score: 0.62      |\n",
    "| Lasso                            |  MSE: 0.47            |\n",
    "|                                  |  MAE: 0.56            |\n",
    "|                                  |  R2:  0.62            |\n",
    "|----------------------------------|-----------------------|\n",
    "|                                  | train score: 0.77     |\n",
    "|                                  | test score: 0.78      |\n",
    "| Ridge                            |  MSE: 0.28            |\n",
    "|                                  |  MAE: 0.41            |\n",
    "|                                  |  R2:  0.78            |\n",
    "|----------------------------------|-----------------------|\n",
    "|                                  | train score: 0.76     |\n",
    "|                                  | test score: 0.75      |\n",
    "| Random Forest                    |  MSE: 0.31            |\n",
    "|                                  |  MAE: 0.44            |\n",
    "|                                  |  R2:  0.75            |\n",
    "|----------------------------------|-----------------------|\n",
    "|                                  | train score: 0.70     |\n",
    "|                                  | test score: 0.72      |\n",
    "| Ridge Model + Best Features      |  MSE: 0.34            |\n",
    "|                                  |  MAE: 0.46            |\n",
    "|                                  |  R2:  0.72            |\n",
    "|----------------------------------|-----------------------|\n",
    "\n",
    "\n",
    "- Even we have outliers, MSE score was lower than MAE. While experimenting with RF, the MAE was more stable than MSE.\n",
    "- The Lasso was a good model to prevent overfitting, but MSE and MAE increased almost in 2 times.\n",
    "- The Ridge gave same results as standard Linear Regression. Model is not overfit and errors are low enought.\n",
    "- Random Forest gives higher R2 score and lower error scores, but it is hard to avoid overfitting.\n",
    "- If we take only 6 best features from EDA and see how they would predict the happiness, the best model would be Ridge if we want to avoid overfitting and have nice scores.\n",
    "- Economic features don't overfit, but score are low and errors are high.\n",
    "- ***Overall, the Ridge or Linear Regression were the best models and best features were all features from dataset.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e796da6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
